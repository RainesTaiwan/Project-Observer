# 💻 Project Observer - 硬體需求指南

完整分析運行本專案所需的硬體配置，從入門到專業級。

---

## 📊 快速參考表

| 配置等級 | CPU | RAM | GPU | 儲存空間 | 適用情境 | 預估成本 |
|---------|-----|-----|-----|---------|---------|---------|
| **最低** | 4核心 | 8GB | 無 | 20GB | 測試/學習 | ~$300 |
| **入門** | 4核心 | 16GB | 無/整合 | 30GB | 輕度使用 | ~$500 |
| **推薦** | 6核心 | 16GB | RTX 3060 | 50GB | 日常使用 | ~$1000 |
| **高階** | 8核心 | 32GB | RTX 4070 | 100GB | 長期運行 | ~$2000 |
| **專業** | 12核心+ | 64GB+ | RTX 4090 | 200GB+ | 訓練模型 | ~$4000+ |

---

## 🎯 詳細硬體需求

### 1. CPU 處理器

#### 最低需求 (4 核心)
- **Intel**: Core i5-8400 或更高
- **AMD**: Ryzen 5 3600 或更高
- **功能**: 運行 Docker 容器、Node.js、Python

**實際性能**:
- ✅ 可運行系統
- ⚠️ AI 推理較慢（5-10秒/次）
- ⚠️ Minecraft 可能卡頓

#### 推薦配置 (6-8 核心)
- **Intel**: Core i7-12700 或 i5-13600K
- **AMD**: Ryzen 7 5800X 或 7700X
- **頻率**: 3.5GHz 基礎，4.5GHz+ 加速

**實際性能**:
- ✅ 流暢運行所有容器
- ✅ AI 推理快速（1-2秒/次）
- ✅ Minecraft 60+ FPS

#### 專業配置 (12+ 核心)
- **Intel**: Core i9-13900K
- **AMD**: Ryzen 9 7950X
- **用途**: 同時訓練模型 + 運行遊戲

---

### 2. RAM 記憶體

#### 最低 8GB
```
系統分配:
├── Ubuntu/Windows: 2GB
├── Docker 容器:
│   ├── Minecraft Server: 2GB
│   ├── AI Agent: 1GB
│   ├── ChromaDB: 0.5GB
│   └── Dashboard: 0.5GB
└── 剩餘: 2GB (勉強)
```

**結果**: ⚠️ 可運行但容易卡頓，AI 推理較慢

#### 推薦 16GB
```
系統分配:
├── Ubuntu/Windows: 3GB
├── Docker 容器:
│   ├── Minecraft Server: 3GB
│   ├── AI Agent: 2GB
│   ├── ChromaDB: 1GB
│   └── Dashboard: 1GB
├── Ollama (本地 AI): 4GB
└── 剩餘: 2GB (舒適)
```

**結果**: ✅ 流暢運行，推薦配置

#### 高階 32GB+
```
優勢:
✅ 可運行 Llama 3.1 70B 大模型
✅ 同時運行多個 AI Agent
✅ 訓練/微調模型時不會 OOM
✅ 可運行更多容器/服務
```

---

### 3. GPU 顯示卡

#### 無 GPU (整合顯示)
**可用模型**:
- ✅ Phi-3 Mini (3.8B)
- ✅ Llama 3.2 3B
- ⚠️ Llama 3.1 8B (很慢)

**推理速度**: 15-30 秒/次
**適合**: 測試系統功能

#### 入門級 GPU (GTX 1660 / RTX 3050)
**規格**:
- VRAM: 6GB
- CUDA: 支援

**可用模型**:
- ✅ Llama 3.1 8B (量化版)
- ✅ Mistral 7B
- ✅ Qwen 2.5 7B

**推理速度**: 2-4 秒/次
**適合**: 日常使用

#### 推薦 GPU (RTX 3060 / 4060)
**規格**:
- VRAM: 12GB / 8GB
- CUDA: 最新

**可用模型**:
- ✅ Llama 3.1 8B (完整版)
- ✅ 所有 7B-8B 模型
- ✅ 可微調 3B-7B 模型

**推理速度**: 0.5-1.5 秒/次
**適合**: 推薦配置，性價比最高

#### 高階 GPU (RTX 4070 / 4070 Ti)
**規格**:
- VRAM: 12GB / 16GB
- 性能: RTX 3060 的 2 倍

**可用模型**:
- ✅ Llama 3.1 70B (量化版)
- ✅ 所有 8B 模型全速
- ✅ 可微調 8B 模型

**推理速度**: 0.3-0.8 秒/次

#### 專業級 GPU (RTX 4090)
**規格**:
- VRAM: 24GB
- 性能: 目前最強消費級

**可用模型**:
- ✅ Llama 3.1 70B (完整版)
- ✅ 任何開源模型
- ✅ 可微調 70B 模型
- ✅ 同時運行多個模型

**推理速度**: 0.2-0.5 秒/次
**適合**: 專業 AI 開發

---

### 4. 儲存空間

#### 基礎需求 (20GB)
```
空間分配:
├── 系統與 Docker: 5GB
├── Minecraft Server: 2GB
├── AI 模型 (Phi-3): 2GB
├── ChromaDB 數據: 1GB
├── 技能與日誌: 2GB
└── 預留空間: 8GB
```

**適合**: 短期測試

#### 推薦空間 (50GB)
```
空間分配:
├── 系統與 Docker: 10GB
├── Minecraft Server: 5GB (世界數據)
├── AI 模型:
│   ├── Llama 3.1 8B: 5GB
│   ├── Mistral 7B: 4GB
│   └── 備用模型: 5GB
├── ChromaDB 數據: 10GB (長期記憶)
├── 技能庫: 5GB
├── 日誌與備份: 6GB
└── 預留空間: 10GB
```

**適合**: 日常使用

#### 專業空間 (200GB+)
```
適合:
✅ 收集大量訓練數據
✅ 存儲多個大型模型
✅ 長期運行保留完整歷史
✅ 多個 Minecraft 世界
```

**建議**: 使用 SSD 提升性能

---

## 🖥️ 完整配置方案

### 方案 A: 學生/入門預算 ($500)

```yaml
用途: 學習 AI、測試系統
預算: NT$ 15,000

硬體配置:
  CPU: AMD Ryzen 5 5600G (整合顯示)
  RAM: 16GB DDR4
  儲存: 256GB SSD
  GPU: 無 (使用整合顯示)
  主機板: B550M
  電源: 450W

AI 配置:
  模型: Phi-3 Mini 或 Llama 3.2 3B
  推理: CPU only
  速度: 15-20 秒/決策

實際體驗:
  ✅ 系統可運行
  ✅ 可觀察 AI 學習過程
  ⚠️ 推理較慢
  ⚠️ 不建議微調模型
```

### 方案 B: 推薦配置 ($1000)

```yaml
用途: 日常使用，流暢體驗
預算: NT$ 30,000

硬體配置:
  CPU: AMD Ryzen 5 7600 或 Intel i5-13400F
  RAM: 16GB DDR5
  儲存: 512GB NVMe SSD
  GPU: RTX 3060 12GB 或 RTX 4060 8GB
  主機板: B650 / B760
  電源: 650W 80+ Bronze

AI 配置:
  模型: Llama 3.1 8B 或 Mistral 7B
  推理: GPU 加速
  速度: 1-2 秒/決策

實際體驗:
  ✅✅ 完全流暢
  ✅✅ 推理快速
  ✅ 可進行簡單微調
  ✅ 長期使用無壓力
  
性價比: ⭐⭐⭐⭐⭐ (最推薦！)
```

### 方案 C: 高階配置 ($2000)

```yaml
用途: 專業開發，訓練模型
預算: NT$ 60,000

硬體配置:
  CPU: AMD Ryzen 7 7800X3D 或 Intel i7-13700K
  RAM: 32GB DDR5
  儲存: 1TB NVMe SSD + 2TB HDD
  GPU: RTX 4070 12GB 或 RTX 4070 Ti 16GB
  主機板: X670 / Z790
  電源: 850W 80+ Gold
  散熱: 水冷 AIO

AI 配置:
  模型: Llama 3.1 70B (量化) 或多個 8B 模型
  推理: 極速 GPU 加速
  速度: 0.5-1 秒/決策

實際體驗:
  ✅✅✅ 專業級性能
  ✅✅ 可訓練大型模型
  ✅✅ 同時運行多個 Agent
  ✅ 4K 遊戲 + AI 同時運行
```

### 方案 D: 專業工作站 ($4000+)

```yaml
用途: AI 研究，商業應用
預算: NT$ 120,000+

硬體配置:
  CPU: AMD Threadripper 或 Intel i9-13900KS
  RAM: 64GB+ DDR5
  儲存: 2TB NVMe SSD (Gen 4) + 4TB+ HDD
  GPU: RTX 4090 24GB
  主機板: TRX50 / Z790 Extreme
  電源: 1200W 80+ Platinum
  散熱: 高階水冷
  機箱: 全塔靜音機箱

AI 配置:
  模型: Llama 3.1 70B 完整版
  推理: 超快速推理
  速度: 0.2-0.5 秒/決策
  
額外能力:
  ✅ 可訓練 70B 模型
  ✅ 同時運行 5+ AI Agent
  ✅ 大規模數據處理
  ✅ 商業級穩定性
```

---

## 💡 不同硬體的實際體驗對比

### AI 決策速度測試

測試情境: 「我看到遠處有村莊，血量 15/20，背包有木劍。我應該做什麼？」

| 硬體配置 | 模型 | 首次決策 | 後續決策 | 體驗評分 |
|---------|------|---------|---------|---------|
| CPU only (8GB) | Phi-3 Mini | 25秒 | 20秒 | ⭐⭐ |
| CPU only (16GB) | Llama 3.2 3B | 18秒 | 15秒 | ⭐⭐⭐ |
| RTX 3060 | Llama 3.1 8B | 2秒 | 1秒 | ⭐⭐⭐⭐⭐ |
| RTX 4070 | Llama 3.1 8B | 1秒 | 0.5秒 | ⭐⭐⭐⭐⭐ |
| RTX 4090 | Llama 3.1 70B | 3秒 | 1.5秒 | ⭐⭐⭐⭐⭐ |

### Minecraft 遊戲體驗

| 硬體配置 | FPS | 渲染距離 | 體驗 |
|---------|-----|---------|------|
| 整合顯示 (8GB) | 30-45 | 8 chunks | 可玩但不流暢 |
| 整合顯示 (16GB) | 45-60 | 10 chunks | 基本流暢 |
| GTX 1660 | 60-90 | 12 chunks | 流暢 |
| RTX 3060 | 120+ | 16 chunks | 非常流暢 |
| RTX 4070+ | 200+ | 32 chunks | 極致體驗 |

---

## 🔋 電力消耗估算

### 待機功耗
```
入門配置: 80W
推薦配置: 120W  
高階配置: 180W
專業配置: 250W+
```

### 滿載功耗
```
入門配置: 200W
推薦配置: 350W (RTX 3060)
高階配置: 500W (RTX 4070)
專業配置: 700W+ (RTX 4090)
```

### 每月電費 (24小時運行)
```
台灣電價: ~5元/度

入門配置: 
  (120W × 24h × 30天) / 1000 × 5元 = 432元/月

推薦配置:
  (180W × 24h × 30天) / 1000 × 5元 = 648元/月

高階配置:
  (250W × 24h × 30天) / 1000 × 5元 = 900元/月
```

💡 **省電建議**: AI Agent 不需要 24 小時運行，建議每天運行 8-12 小時

---

## 📱 筆記型電腦可以嗎？

### 可以運行的筆電配置

#### 入門級筆電
```yaml
最低要求:
  CPU: Intel i5-12500H / AMD Ryzen 5 6600H
  RAM: 16GB
  GPU: RTX 3050 / GTX 1650 或整合顯示
  
實際體驗:
  ✅ 可運行系統
  ⚠️ 推理較慢 (5-10秒)
  ⚠️ 風扇會很大聲
  ⚠️ 電池續航短 (1-2小時)
```

#### 推薦遊戲筆電
```yaml
理想配置:
  CPU: Intel i7-13700H / AMD Ryzen 7 7840HS
  RAM: 32GB
  GPU: RTX 4060 Laptop / RTX 4070 Laptop
  
實際體驗:
  ✅✅ 流暢運行
  ✅ 推理快速 (1-2秒)
  ✅ 可攜帶展示
  ⚠️ 散熱需要注意
  
推薦型號:
  • ASUS ROG Zephyrus G14
  • Lenovo Legion 5 Pro
  • MSI Stealth 15
  • Razer Blade 14
```

### 筆電使用注意事項

⚠️ **散熱問題**
```bash
# 長時間運行建議:
1. 使用散熱墊
2. 確保通風良好
3. 調整電源模式為「平衡」
4. 監控溫度 (不超過 85°C)

# Linux 監控溫度
watch -n 1 sensors

# 限制 CPU 功耗 (避免過熱)
sudo cpupower frequency-set --max 3.0GHz
```

⚠️ **電源管理**
```bash
# 長時間運行必須接電源
# 電池模式下性能會大幅降低

# 使用電源管理工具
sudo apt install tlp
sudo tlp start
```

---

## 🌐 雲端運行方案

如果本地硬體不足，可考慮雲端服務器：

### AWS EC2
```yaml
配置: g4dn.xlarge (4 vCPU, 16GB RAM, T4 GPU)
費用: ~$0.526/小時 = $378/月
優勢: 隨時開關機，按需付費

配置: g5.xlarge (4 vCPU, 16GB RAM, A10G GPU)
費用: ~$1.006/小時 = $722/月
優勢: 更強的 GPU 性能
```

### Google Cloud Platform
```yaml
配置: n1-standard-4 + T4 GPU
費用: ~$0.35/小時 = $252/月
優勢: 整合 TPU 選項
```

### 自建方案 vs 雲端對比

```
一年成本比較:

本地 RTX 3060 配置:
  初期投資: NT$ 30,000
  電費: 648元 × 12 = 7,776元
  總計第一年: 37,776元
  
AWS g4dn.xlarge:
  月費: $378 × 12 = $4,536
  換算台幣: 約 136,000元/年
  
結論: 本地配置 5 個月回本！
```

---

## ✅ 我的推薦

### 🎯 如果你是學生 / 預算有限
```
配置: 方案 A
投資: ~15,000 台幣
模型: Phi-3 Mini
體驗: 可用，但較慢
建議: 先用這個學習，未來升級
```

### 🎯 如果你認真想長期使用
```
配置: 方案 B (RTX 3060 + 16GB)
投資: ~30,000 台幣
模型: Llama 3.1 8B
體驗: 流暢，推薦！
建議: 性價比最高，強烈推薦 ⭐⭐⭐⭐⭐
```

### 🎯 如果你要專業開發 / 訓練模型
```
配置: 方案 C (RTX 4070 + 32GB)
投資: ~60,000 台幣
模型: Llama 3.1 70B
體驗: 專業級
建議: 可訓練自己的模型
```

### 🎯 如果你預算無上限
```
配置: 方案 D (RTX 4090 + 64GB)
投資: 120,000+ 台幣
模型: 任何模型
體驗: 頂級
建議: 商業應用或 AI 研究
```

---

## 🛒 購買建議

### 優先級排序
1. **RAM 16GB** - 最重要！
2. **SSD 存儲** - 大幅提升性能
3. **GPU (RTX 3060+)** - 如果要用本地 AI
4. **更好的 CPU** - 最後考慮

### 升級策略

```
起步配置 (15,000):
  CPU: Ryzen 5 5600G
  RAM: 16GB
  儲存: 256GB SSD
  GPU: 整合顯示

6個月後升級 (+15,000):
  + GPU: RTX 3060 12GB

1年後升級 (+8,000):
  + RAM: 32GB (16GB → 32GB)
  + 儲存: +1TB SSD

總投資: 38,000 元
最終配置: 高階配置
```

---

## 📊 快速決策流程圖

```
開始
  │
  ├─ 預算 < 20,000? 
  │    └─ YES → 方案 A (整合顯示 + 16GB)
  │    └─ NO  → 繼續
  │
  ├─ 預算 < 40,000?
  │    └─ YES → 方案 B (RTX 3060 + 16GB) ⭐推薦
  │    └─ NO  → 繼續
  │
  ├─ 需要訓練模型?
  │    └─ YES → 方案 C/D (RTX 4070/4090 + 32GB+)
  │    └─ NO  → 方案 B 即可
  │
  └─ 完成
```

---

## 🔗 相關文檔

- [本地 AI 設置指南](LOCAL_AI_GUIDE.md)
- [OpenAI vs 本地 AI 對比](OPENAI_VS_LOCAL.md)
- [一鍵設置腳本](setup_local_ai.sh)

---

**總結**: 16GB RAM + RTX 3060 是性價比最高的配置！約 30,000 台幣即可流暢運行。💯
